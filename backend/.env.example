# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
OLLAMA_ENDPOINT=http://localhost:11434

# Important: Never commit this file to version control
# Make sure .env is listed in your .gitignore file

# Model Endpoints
USE_LOCAL_MODELS=false
PREFER_API_CALLS=true
ENABLE_FALLBACK=true

# Model Configurations
PREFER_LOCAL_MODELS=true                       # Prefer Ollama over API calls when possible

# Endpoints
HUGGINGFACE_API_ENDPOINT=https://api-inference.huggingface.co/models

# Server Configuration
FLASK_APP=app.py
FLASK_ENV=development
PORT=5002

# Database Configuration
DB_TYPE=sqlite                                # Options: sqlite, postgres
DATABASE_URL=sqlite:///app.db

# PostgreSQL Configuration
POSTGRES_DB=smartprobono
POSTGRES_USER=postgres
POSTGRES_PASSWORD=secure_password_here
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# Queue Cache Settings
QUEUE_CACHE_TTL=60                            # Seconds before refreshing in-memory queue from DB

# Security
SECRET_KEY=your_secret_key_here
JWT_SECRET_KEY=your_jwt_secret_here

# Rate Limiting
RATE_LIMIT_DEFAULT="200 per day, 50 per hour"
RATE_LIMIT_STORAGE="memory://"                # Options: memory://, redis://localhost:6379/0

# Logging
LOG_LEVEL=DEBUG 